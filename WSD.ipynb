{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPGOidwVmIddbiL1pPEIDVE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/siddhesh1503/NLP/blob/main/WSD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rC9JsJRqW6Cu"
      },
      "outputs": [],
      "source": [
        "!pip install nltk scikit-learn pandas\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "id": "o_ejiVC7XEBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "\n",
        "def normalize(words):\n",
        "    return [w.lower().strip(string.punctuation) for w in words if w.strip(string.punctuation)]\n",
        "\n",
        "def simplified_lesk(context_sentence, ambiguous_word, pos=None):\n",
        "    context = normalize(word_tokenize(context_sentence))\n",
        "    max_overlap = 0\n",
        "    best_sense = None\n",
        "\n",
        "    synsets = wn.synsets(ambiguous_word, pos=pos) if pos else wn.synsets(ambiguous_word)\n",
        "    if not synsets:\n",
        "        return None\n",
        "\n",
        "    for sense in synsets:\n",
        "        signature = []\n",
        "        signature += normalize(word_tokenize(sense.definition() or \"\"))\n",
        "        for ex in sense.examples():\n",
        "            signature += normalize(word_tokenize(ex))\n",
        "        signature += [lemma.lower() for lemma in [l.replace('_', ' ') for l in sense.lemma_names()]]\n",
        "        overlap = len(set(signature) & set(context))\n",
        "        if overlap > max_overlap:\n",
        "            max_overlap = overlap\n",
        "            best_sense = sense\n",
        "\n",
        "    return best_sense\n",
        "\n",
        "# Test sentences\n",
        "sents = [\n",
        "    (\"I went to the bank to deposit my paycheck.\", \"bank\"),\n",
        "    (\"The river overflowed the bank after the heavy rain.\", \"bank\"),\n",
        "    (\"He sat on the bank and watched the ducks.\", \"bank\"),\n",
        "    (\"I need to charge my phone\", \"charge\"),\n",
        "    (\"The soldier received a charge by the court\", \"charge\")\n",
        "]\n",
        "\n",
        "for sent, word in sents:\n",
        "    sense = simplified_lesk(sent, word)\n",
        "    print(f\"Sentence: {sent}\")\n",
        "    if sense:\n",
        "        print(f\"Predicted sense: {sense.name()} -> {sense.definition()}\\n\")\n",
        "    else:\n",
        "        print(\"No sense found.\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xI5oChWPXImg",
        "outputId": "eaf8d351-9bfe-4b66-c2b6-8d893b6d3f2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: I went to the bank to deposit my paycheck.\n",
            "Predicted sense: depository_financial_institution.n.01 -> a financial institution that accepts deposits and channels the money into lending activities\n",
            "\n",
            "Sentence: The river overflowed the bank after the heavy rain.\n",
            "Predicted sense: bank.n.01 -> sloping land (especially the slope beside a body of water)\n",
            "\n",
            "Sentence: He sat on the bank and watched the ducks.\n",
            "Predicted sense: bank.n.01 -> sloping land (especially the slope beside a body of water)\n",
            "\n",
            "Sentence: I need to charge my phone\n",
            "Predicted sense: charge.v.24 -> energize a battery by passing a current through it in the direction opposite to discharge\n",
            "\n",
            "Sentence: The soldier received a charge by the court\n",
            "Predicted sense: charge.v.12 -> pay with a credit card; pay with plastic money; postpone payment by recording a purchase as a debt\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import nltk\n",
        "from nltk import word_tokenize, pos_tag\n",
        "import re\n",
        "\n",
        "def get_context_window(sentence, target_idx, window=3):\n",
        "    tokens = word_tokenize(sentence)\n",
        "    left = max(0, target_idx - window)\n",
        "    right = min(len(tokens), target_idx + window + 1)\n",
        "    return tokens[left:right]\n",
        "\n",
        "def find_target_index(sentence, target_word):\n",
        "    tokens = word_tokenize(sentence)\n",
        "    for i,t in enumerate(tokens):\n",
        "        if re.fullmatch(re.escape(target_word), t, flags=re.IGNORECASE):\n",
        "            return i\n",
        "    for i,t in enumerate(tokens):\n",
        "        if t.lower().startswith(target_word.lower()):\n",
        "            return i\n",
        "    return 0\n",
        "\n",
        "def train_evaluate(df, test_size=0.2, random_state=42, window=3):\n",
        "    X_sentences = df['sentence'].tolist()\n",
        "    targets = df['target_word'].tolist()\n",
        "    y = df['sense'].astype(str).tolist()\n",
        "\n",
        "    # Extract context windows\n",
        "    context_texts = []\n",
        "    for sent, target in zip(X_sentences, targets):\n",
        "        idx = find_target_index(sent, target)\n",
        "        context_texts.append(\" \".join(get_context_window(sent, idx, window=window)))\n",
        "\n",
        "    vectorizer = CountVectorizer(max_features=2000)\n",
        "    X_vec = vectorizer.fit_transform(context_texts)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_vec, y, test_size=test_size,\n",
        "                                                        random_state=random_state,\n",
        "                                                        stratify=y if len(set(y))>1 else None)\n",
        "\n",
        "    clf = MultinomialNB()\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_test, y_pred, zero_division=0))\n",
        "    return clf, vectorizer\n",
        "\n",
        "# Example dataset\n",
        "data = [\n",
        "    (\"I went to the bank to deposit my paycheck.\", \"bank\", \"bank_financial\"),\n",
        "    (\"The river overflowed the bank after the heavy rain.\", \"bank\", \"bank_river\"),\n",
        "    (\"He sat on the bank and watched the ducks.\", \"bank\", \"bank_river\"),\n",
        "    (\"She opened an account at the bank this morning.\", \"bank\", \"bank_financial\"),\n",
        "    (\"The boat was pulled up onto the river bank.\", \"bank\", \"bank_river\"),\n",
        "    (\"He withdrew cash from the bank ATM.\", \"bank\", \"bank_financial\"),\n",
        "    (\"We picnicked on the grassy bank by the river.\", \"bank\", \"bank_river\"),\n",
        "]\n",
        "df = pd.DataFrame(data, columns=['sentence','target_word','sense'])\n",
        "clf, vect = train_evaluate(df, test_size=0.4, window=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUGGdDUwX0Ap",
        "outputId": "26ec50fe-234c-4fe0-c852-6a9c1282d746"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6666666666666666\n",
            "Classification Report:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "bank_financial       0.00      0.00      0.00         1\n",
            "    bank_river       0.67      1.00      0.80         2\n",
            "\n",
            "      accuracy                           0.67         3\n",
            "     macro avg       0.33      0.50      0.40         3\n",
            "  weighted avg       0.44      0.67      0.53         3\n",
            "\n"
          ]
        }
      ]
    }
  ]
}